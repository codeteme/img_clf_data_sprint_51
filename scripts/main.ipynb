{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!chmod 600 ../kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle datasets download temesgentewolde/animal-dataset-intermediate -p ../data/raw"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip ../data/raw/animal-dataset-intermediate.zip -d ../data/raw"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!rm ../data/raw/animal-dataset-intermediate.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-22T14:38:52.737915Z","iopub.status.busy":"2021-10-22T14:38:52.737383Z","iopub.status.idle":"2021-10-22T14:38:57.514472Z","shell.execute_reply":"2021-10-22T14:38:57.513714Z","shell.execute_reply.started":"2021-10-22T14:38:52.737873Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import numpy as np\n","import pathlib\n","import os\n","import PIL\n","import PIL.Image\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_dir = \"../data/raw/animal_dataset_intermediate/train\"\n","data_dir = pathlib.Path(data_dir)\n","print(data_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-10-22T14:38:49.927008Z","iopub.status.idle":"2021-10-22T14:38:49.927780Z","shell.execute_reply":"2021-10-22T14:38:49.927556Z","shell.execute_reply.started":"2021-10-22T14:38:49.927530Z"},"trusted":true},"outputs":[],"source":["num_skipped = 0\n","for folder_name in (\"elefante\", \"farfalla\", \"mucca\", \"pecora\", \"scoiattolo\"):\n","    folder_path = os.path.join(data_dir, folder_name)\n","    for fname in os.listdir(folder_path):\n","        fpath = os.path.join(folder_path, fname)\n","        try:\n","            fobj = open(fpath, \"rb\")\n","            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n","        finally:\n","            fobj.close()\n","\n","        if not is_jfif:\n","            num_skipped += 1\n","            # Delete corrupted image\n","            os.remove(fpath)\n","\n","print(\"Deleted %d images\" % num_skipped)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-22T14:39:00.021176Z","iopub.status.busy":"2021-10-22T14:39:00.020370Z","iopub.status.idle":"2021-10-22T14:39:01.635489Z","shell.execute_reply":"2021-10-22T14:39:01.634679Z","shell.execute_reply.started":"2021-10-22T14:39:00.021127Z"},"trusted":true},"outputs":[],"source":["image_count = len(list(data_dir.glob('*/*.jpg')) + list(data_dir.glob('*/*.jpeg')))\n","print(\"Imported image_count: \", image_count)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["elephant = list(data_dir.glob('elefante/*'))\n","PIL.Image.open(str(elephant[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-22T14:39:08.200873Z","iopub.status.busy":"2021-10-22T14:39:08.200117Z","iopub.status.idle":"2021-10-22T14:39:20.608190Z","shell.execute_reply":"2021-10-22T14:39:20.607392Z","shell.execute_reply.started":"2021-10-22T14:39:08.200817Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","img_height = 256\n","img_width = 256\n","\n","\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2, # We train our model using 80% of the train_ds and test on the remaining 20%.\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["Let's check if OS and PIL libraries are correctly reading and displying the images. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-22T14:40:11.802160Z","iopub.status.busy":"2021-10-22T14:40:11.801790Z","iopub.status.idle":"2021-10-22T14:40:11.814454Z","shell.execute_reply":"2021-10-22T14:40:11.813774Z","shell.execute_reply.started":"2021-10-22T14:40:11.802120Z"},"trusted":true},"outputs":[],"source":["class_names = ['elefante', 'farfalla', 'mucca', 'pecora', 'scoiattolo']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 10))\n","for images, labels in train_ds.take(1):\n","  for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(class_names[labels[i]])\n","    plt.axis(\"off\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get images(x) and lables(y) of a given batchdatasets\n","def get_image_label(ds): \n","    x_train_ = []\n","    y_train_ = []\n","    for element in ds.as_numpy_iterator(): \n","        x_train_.append(element[0])\n","        y_train_.append(element[1])\n","    x_train = np.concatenate(x_train_)\n","    y_train = np.concatenate(y_train_)\n","    \n","    return (x_train, y_train)\n","\n","x_train, y_train = get_image_label(train_ds)\n","x_val, y_val = get_image_label(val_ds)\n","\n","print(type(x_train), type(y_train))\n","print(x_train.shape, y_train.shape, x_train.ndim)\n","print(x_val.shape, y_val.shape, x_val.ndim)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["assert isinstance(x_train, (np.ndarray, np.generic))\n","assert isinstance(y_train, (np.ndarray, np.generic))\n","assert isinstance(x_val, (np.ndarray, np.generic))\n","assert isinstance(y_val, (np.ndarray, np.generic))\n","\n","assert x_train.ndim, x_val == 4\n","assert y_train.ndim, y_train.ndim == 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TODO: Data viz to show data imbalance - bar graph\n","\n","plt.figure(figsize=(8, 3))\n","splot = sns.countplot(y_train)\n","for p in splot.patches:\n","    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), \n","    ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n","\n","splot.set_xticklabels(class_names)\n","splot.set_xlabel(\"Classes\")\n","splot.set_ylabel(\"Count\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.utils import resample \n","\n","print(\"-\" * 70)\n","print('Input shape before resampling: ' ,x_train.shape, y_train.shape)\n","\n","#..reshape (flatten) x_train for SMOTE resampling\n","nsamples, k, nx, ny = x_train.shape\n","x_train = x_train.reshape((nsamples,k*nx*ny))\n","x_train.shape\n","\n","from imblearn.over_sampling import SMOTE\n","smote = SMOTE('all')\n","x_train, y_train = smote.fit_resample(x_train, y_train)\n","\n","print(\"-\" * 70)\n","print('Input shape after sampling: ' ,x_train.shape, y_train.shape)\n","print('Class distribution after over-sampling: ')\n","for i in range(len(class_names)):\n","    print(f'Number of class {class_names[i]} examples before:{x_train[y_train == i].shape[0]}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 3))\n","splot = sns.countplot(y_train)\n","for p in splot.patches:\n","    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), \n","    ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n","\n","splot.set_xticklabels(class_names)\n","splot.set_xlabel(\"Classes\")\n","splot.set_ylabel(\"Count\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# return to original 4D shape\n","x_train = x_train.reshape(7325, k, nx, ny)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-22T14:41:07.352482Z","iopub.status.busy":"2021-10-22T14:41:07.351747Z","iopub.status.idle":"2021-10-22T14:41:07.383205Z","shell.execute_reply":"2021-10-22T14:41:07.382477Z","shell.execute_reply.started":"2021-10-22T14:41:07.352440Z"},"trusted":true},"outputs":[],"source":["data_augmentation = keras.Sequential([\n","    layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width,3)),\n","    layers.RandomRotation(0.1),layers.RandomZoom(0.1),\n","    layers.RandomContrast((0.1, 0.9)),\n","    ])\n","\n","assert(x_train.ndim == 4) # Check if augementation affected shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","root_logdir = os.path.join(os.curdir, \"my_logs\")\n","\n","def get_run_logdir():\n","    import time\n","    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n","    return os.path.join(root_logdir, run_id)\n","\n","run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'\n","\n","tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir=./my_logs --port=6006"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_classes = 5\n","\n","model = tf.keras.Sequential([\n","  data_augmentation,\n","  tf.keras.layers.Rescaling(1./255),\n","  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","  tf.keras.layers.MaxPooling2D(),\n","  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","  tf.keras.layers.MaxPooling2D(),\n","  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","  tf.keras.layers.MaxPooling2D(),\n","  layers.Dropout(0.2), # Dropout https://www.tensorflow.org/tutorials/images/classification#dropout\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dense(num_classes)\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(\n","  optimizer='adam',\n","  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  metrics=['accuracy']\n","  )\n"]},{"cell_type":"markdown","metadata":{},"source":["# Two callbacks options to implement early Stopping to avoid overfitting. \n","\n","#1. keras.callbacks.ModelCheckpoint() saves the model when its performance on the validation set is the best so far\n","\n","#2. keras.callbacks.EarlyStopping() interrupts training when it measures no progress on the validation set for a number of epochs (defined by the patience argument), and it will optionally roll back to the best model.\n","\n","It's possible to  combine both callbacks to save checkpoints of your model (in case the computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# epochs = 50\n","# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"saved_model/keras_model.h5\", save_best_only=True)\n","# early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n","#                                                   restore_best_weights=True)\n","# history =  model.fit(\n","#   x_train, y_train,\n","#   validation_data=(x_val, y_val),\n","#   epochs=epochs,\n","#   callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb]\n","# )\n"]},{"cell_type":"markdown","metadata":{},"source":["checkpoint_cb saves the best model. Just in case, though, we'll also save the final model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model.save('../saved_model/best_model') "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model.evaluate(x_val, y_val, verbose=2) # ~78% accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model = tf.keras.models.load_model('../my_keras_model.h5')\n","new_model.evaluate(x_val, y_val, verbose=2) # ~78% accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO: Calculate validation accuracy per class. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","pd.options.display.max_colwidth = 999"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_data_dir = \"../data/raw/animal_dataset_intermediate/test\"\n","test_data_dir = pathlib.Path(test_data_dir)\n","print(test_data_dir)\n","\n","image_count = len(list(test_data_dir.glob('*.jpg')) + list(test_data_dir.glob('*.jpeg')))\n","print(\"Imported image_count: \", image_count)\n","\n","picture = list(test_data_dir.glob('*'))\n","PIL.Image.open(str(picture[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_submission_filename = pd.read_csv(\"../data/raw/animal_dataset_intermediate/Testing_set_animals.csv\")\n","\n","classes = []\n","\n","df_len = df_submission_filename.shape[0]\n","for i in range(df_len): \n","    path = os.path.join(test_data_dir, df_submission_filename.loc[i][0])\n","    img = tf.keras.utils.load_img(\n","        path, grayscale=False, color_mode='rgb', target_size=(img_height, img_width),\n","        interpolation='nearest'\n","    )\n","    img_array = tf.keras.utils.img_to_array(img)\n","    img_array = img_array.reshape(1, k, nx, ny)\n","    predict_img = model.predict(img_array) \n","    classes_img = np.argmax(predict_img,axis=1)\n","    classes.append(classes_img[0])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_submission_filename['target'] = [class_names[num] for num in list(classes)]\n","df_submission_filename.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_submission_filename.to_csv(\"submission/submission.csv\", index=False)"]}],"metadata":{"interpreter":{"hash":"7d9279c439293cd56693e7c05115c53cbb1633ee63d7052d68a345e17a860490"},"kernelspec":{"display_name":"Python 3.9.6 64-bit ('csx433env': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
